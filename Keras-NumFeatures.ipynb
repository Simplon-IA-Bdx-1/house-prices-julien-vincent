{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow import random as tf_random\n",
    "\n",
    "# ignore Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('files_csv/train.csv')\n",
    "test = pd.read_csv('files_csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train shape (1460, 81)\n",
      " test shape (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(f' train shape {train.shape}')\n",
    "print(f' test shape {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution de SalePrice et Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4a6c024710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4a6c867450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "sns.distplot(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  On garde que les features numériques de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.select_dtypes(exclude=['object'])\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Id',axis = 1, inplace = True)\n",
    "train.drop('MSSubClass',axis = 1, inplace = True) # fausse variable numérique\n",
    "train.fillna(0,inplace=True) # a test par zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>12.247699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>12.109016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>12.317171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>11.849405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>12.429220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0         65.0     8450            7            5       2003          2003   \n",
       "1         80.0     9600            6            8       1976          1976   \n",
       "2         68.0    11250            7            5       2001          2002   \n",
       "3         60.0     9550            7            5       1915          1970   \n",
       "4         84.0    14260            8            5       2000          2000   \n",
       "\n",
       "   MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  WoodDeckSF  \\\n",
       "0       196.0         706           0        150  ...           0   \n",
       "1         0.0         978           0        284  ...         298   \n",
       "2       162.0         486           0        434  ...           0   \n",
       "3         0.0         216           0        540  ...           0   \n",
       "4       350.0         655           0        490  ...         192   \n",
       "\n",
       "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0           61              0          0            0         0        0   \n",
       "1            0              0          0            0         0        0   \n",
       "2           42              0          0            0         0        0   \n",
       "3           35            272          0            0         0        0   \n",
       "4           84              0          0            0         0        0   \n",
       "\n",
       "   MoSold  YrSold  SalePrice  \n",
       "0       2    2008  12.247699  \n",
       "1       5    2007  12.109016  \n",
       "2       9    2008  12.317171  \n",
       "3       2    2006  11.849405  \n",
       "4      12    2008  12.429220  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pareil pour test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.select_dtypes(exclude=['object'])\n",
    "test_ID = test.Id\n",
    "test.fillna(0,inplace=True) # a test par zero \n",
    "test.drop('Id',axis = 1, inplace = True)\n",
    "test.drop('MSSubClass',axis = 1, inplace = True) # fausse variable numérique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>730.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>312.0</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>482.0</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>470.0</td>\n",
       "      <td>360</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>506.0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0         80.0    11622            5            6       1961          1961   \n",
       "1         81.0    14267            6            6       1958          1958   \n",
       "2         74.0    13830            5            5       1997          1998   \n",
       "3         78.0     9978            6            6       1998          1998   \n",
       "4         43.0     5005            8            5       1992          1992   \n",
       "\n",
       "   MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  GarageArea  WoodDeckSF  \\\n",
       "0         0.0       468.0       144.0      270.0  ...       730.0         140   \n",
       "1       108.0       923.0         0.0      406.0  ...       312.0         393   \n",
       "2         0.0       791.0         0.0      137.0  ...       482.0         212   \n",
       "3        20.0       602.0         0.0      324.0  ...       470.0         360   \n",
       "4         0.0       263.0         0.0     1017.0  ...       506.0           0   \n",
       "\n",
       "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0            0              0          0          120         0        0   \n",
       "1           36              0          0            0         0    12500   \n",
       "2           34              0          0            0         0        0   \n",
       "3           36              0          0            0         0        0   \n",
       "4           82              0          0          144         0        0   \n",
       "\n",
       "   MoSold  YrSold  \n",
       "0       6    2010  \n",
       "1       6    2010  \n",
       "2       3    2010  \n",
       "3       6    2010  \n",
       "4       1    2010  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features dans le dataset : ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features dans le dataset : {list(train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features fortement corrélés avec SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['SalePrice','OverallQual', 'GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt']\n",
    "# cols = ['SalePrice','GrLivArea','OverallCond','LotArea','OverallQual','1stFlrSF'] # Features importances XgBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train[(train['LotFrontage']>300)].index).reset_index(drop=True)\n",
    "train = train.drop(train[(train['LotArea']>150000)].index).reset_index(drop=True)\n",
    "train = train.drop(train[(train['BsmtFinSF1']>2000) & (train['SalePrice']<12.5)].index).reset_index(drop=True)\n",
    "train = train.drop(train[(train['GarageArea']>1200) & (train['SalePrice']<12.5)].index).reset_index(drop=True)\n",
    "train = train.drop(train[(train['WoodDeckSF']>600) & (train['SalePrice']<12)].index).reset_index(drop=True)\n",
    "train = train.drop(train[(train['OpenPorchSF']>500) & (train['SalePrice']<11)].index).reset_index(drop=True)\n",
    "train = train.drop(train[(train['GarageCars']>3) & (train['SalePrice']<12.5)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train & y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'SalePrice'\n",
    "y_train_full = train[target_column].values\n",
    "X_train_full = train.drop(target_column, axis=1).values\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random as np_random\n",
    "SEED = 42\n",
    "np_random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_X.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler_X.transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_Y_log = StandardScaler()\n",
    "scaler_Y_log.fit(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log_scaled = scaler_Y_log.transform(y_train.reshape(-1,1))\n",
    "y_val_log_scaled = scaler_Y_log.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Doc : learning_rate: float >= 0. Initial learning rate, defaults to 1. It is recommended to leave it at the default value.\n",
    "* Lolo : \"Divise tout par 100\" =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_train.shape[1]\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,input_dim=n_input, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adadelta(learning_rate=0.01, rho=0.95))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KerasRegressor(build_fn=create_model)\n",
    "# epochs = np.array([500, 600,700])\n",
    "# batches = np.array([5,10,15])\n",
    "# param_grid = dict(nb_epoch=epochs, batch_size=batches)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "# grid_result = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               3600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 8,701\n",
      "Trainable params: 8,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1083 samples, validate on 361 samples\n",
      "Epoch 1/500\n",
      "1083/1083 [==============================] - 0s 237us/step - loss: 0.9886 - val_loss: 0.8957\n",
      "Epoch 2/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.9746 - val_loss: 0.8837\n",
      "Epoch 3/500\n",
      "1083/1083 [==============================] - 0s 141us/step - loss: 0.9615 - val_loss: 0.8723\n",
      "Epoch 4/500\n",
      "1083/1083 [==============================] - 0s 172us/step - loss: 0.9491 - val_loss: 0.8614\n",
      "Epoch 5/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.9365 - val_loss: 0.8503\n",
      "Epoch 6/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.9237 - val_loss: 0.8386\n",
      "Epoch 7/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.9101 - val_loss: 0.8264\n",
      "Epoch 8/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.8957 - val_loss: 0.8136\n",
      "Epoch 9/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.8808 - val_loss: 0.8001\n",
      "Epoch 10/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.8647 - val_loss: 0.7856\n",
      "Epoch 11/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.8474 - val_loss: 0.7699\n",
      "Epoch 12/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.8290 - val_loss: 0.7533\n",
      "Epoch 13/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.8098 - val_loss: 0.7363\n",
      "Epoch 14/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.7903 - val_loss: 0.7188\n",
      "Epoch 15/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.7707 - val_loss: 0.7011\n",
      "Epoch 16/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.7502 - val_loss: 0.6822\n",
      "Epoch 17/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.7286 - val_loss: 0.6620\n",
      "Epoch 18/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.7055 - val_loss: 0.6410\n",
      "Epoch 19/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.6819 - val_loss: 0.6195\n",
      "Epoch 20/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.6581 - val_loss: 0.5979\n",
      "Epoch 21/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.6336 - val_loss: 0.5750\n",
      "Epoch 22/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.6076 - val_loss: 0.5513\n",
      "Epoch 23/500\n",
      "1083/1083 [==============================] - 0s 117us/step - loss: 0.5812 - val_loss: 0.5271\n",
      "Epoch 24/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.5545 - val_loss: 0.5031\n",
      "Epoch 25/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.5278 - val_loss: 0.4792\n",
      "Epoch 26/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.5017 - val_loss: 0.4558\n",
      "Epoch 27/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.4762 - val_loss: 0.4328\n",
      "Epoch 28/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.4514 - val_loss: 0.4112\n",
      "Epoch 29/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.4275 - val_loss: 0.3895\n",
      "Epoch 30/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.4034 - val_loss: 0.3676\n",
      "Epoch 31/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.3792 - val_loss: 0.3457\n",
      "Epoch 32/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.3556 - val_loss: 0.3246\n",
      "Epoch 33/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.3337 - val_loss: 0.3047\n",
      "Epoch 34/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.3124 - val_loss: 0.2851\n",
      "Epoch 35/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.2916 - val_loss: 0.2667\n",
      "Epoch 36/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.2726 - val_loss: 0.2495\n",
      "Epoch 37/500\n",
      "1083/1083 [==============================] - 0s 117us/step - loss: 0.2550 - val_loss: 0.2340\n",
      "Epoch 38/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.2393 - val_loss: 0.2203\n",
      "Epoch 39/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.2250 - val_loss: 0.2077\n",
      "Epoch 40/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.2124 - val_loss: 0.1968\n",
      "Epoch 41/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.2017 - val_loss: 0.1877\n",
      "Epoch 42/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.1924 - val_loss: 0.1793\n",
      "Epoch 43/500\n",
      "1083/1083 [==============================] - 0s 165us/step - loss: 0.1843 - val_loss: 0.1722\n",
      "Epoch 44/500\n",
      "1083/1083 [==============================] - 0s 157us/step - loss: 0.1772 - val_loss: 0.1658\n",
      "Epoch 45/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.1707 - val_loss: 0.1601\n",
      "Epoch 46/500\n",
      "1083/1083 [==============================] - 0s 162us/step - loss: 0.1652 - val_loss: 0.1553\n",
      "Epoch 47/500\n",
      "1083/1083 [==============================] - 0s 150us/step - loss: 0.1603 - val_loss: 0.1509\n",
      "Epoch 48/500\n",
      "1083/1083 [==============================] - 0s 209us/step - loss: 0.1559 - val_loss: 0.1470\n",
      "Epoch 49/500\n",
      "1083/1083 [==============================] - 0s 160us/step - loss: 0.1521 - val_loss: 0.1437\n",
      "Epoch 50/500\n",
      "1083/1083 [==============================] - 0s 194us/step - loss: 0.1488 - val_loss: 0.1410\n",
      "Epoch 51/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.1460 - val_loss: 0.1387\n",
      "Epoch 52/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.1436 - val_loss: 0.1368\n",
      "Epoch 53/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.1415 - val_loss: 0.1350\n",
      "Epoch 54/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.1396 - val_loss: 0.1337\n",
      "Epoch 55/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.1381 - val_loss: 0.1324\n",
      "Epoch 56/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.1365 - val_loss: 0.1313\n",
      "Epoch 57/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.1352 - val_loss: 0.1303\n",
      "Epoch 58/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.1340 - val_loss: 0.1294\n",
      "Epoch 59/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.1329 - val_loss: 0.1286\n",
      "Epoch 60/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.1318 - val_loss: 0.1279\n",
      "Epoch 61/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.1307 - val_loss: 0.1272\n",
      "Epoch 62/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.1298 - val_loss: 0.1266\n",
      "Epoch 63/500\n",
      "1083/1083 [==============================] - 0s 144us/step - loss: 0.1289 - val_loss: 0.1260\n",
      "Epoch 64/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.1280 - val_loss: 0.1255\n",
      "Epoch 65/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.1272 - val_loss: 0.1249\n",
      "Epoch 66/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.1264 - val_loss: 0.1243\n",
      "Epoch 67/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.1256 - val_loss: 0.1238\n",
      "Epoch 68/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.1248 - val_loss: 0.1233\n",
      "Epoch 69/500\n",
      "1083/1083 [==============================] - 0s 164us/step - loss: 0.1241 - val_loss: 0.1228\n",
      "Epoch 70/500\n",
      "1083/1083 [==============================] - 0s 157us/step - loss: 0.1233 - val_loss: 0.1223\n",
      "Epoch 71/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.1226 - val_loss: 0.1218\n",
      "Epoch 72/500\n",
      "1083/1083 [==============================] - 0s 153us/step - loss: 0.1219 - val_loss: 0.1214\n",
      "Epoch 73/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.1213 - val_loss: 0.1210\n",
      "Epoch 74/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.1207 - val_loss: 0.1205\n",
      "Epoch 75/500\n",
      "1083/1083 [==============================] - 0s 154us/step - loss: 0.1200 - val_loss: 0.1201\n",
      "Epoch 76/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.1194 - val_loss: 0.1196\n",
      "Epoch 77/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.1187 - val_loss: 0.1192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.1181 - val_loss: 0.1188\n",
      "Epoch 79/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.1175 - val_loss: 0.1183\n",
      "Epoch 80/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.1169 - val_loss: 0.1179\n",
      "Epoch 81/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.1163 - val_loss: 0.1175\n",
      "Epoch 82/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.1157 - val_loss: 0.1171\n",
      "Epoch 83/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.1151 - val_loss: 0.1166\n",
      "Epoch 84/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.1145 - val_loss: 0.1162\n",
      "Epoch 85/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.1140 - val_loss: 0.1158\n",
      "Epoch 86/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.1134 - val_loss: 0.1154\n",
      "Epoch 87/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.1129 - val_loss: 0.1150\n",
      "Epoch 88/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.1124 - val_loss: 0.1147\n",
      "Epoch 89/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.1118 - val_loss: 0.1143\n",
      "Epoch 90/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.1113 - val_loss: 0.1139\n",
      "Epoch 91/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.1108 - val_loss: 0.1136\n",
      "Epoch 92/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.1103 - val_loss: 0.1132\n",
      "Epoch 93/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.1099 - val_loss: 0.1129\n",
      "Epoch 94/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.1094 - val_loss: 0.1125\n",
      "Epoch 95/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.1089 - val_loss: 0.1121\n",
      "Epoch 96/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.1084 - val_loss: 0.1118\n",
      "Epoch 97/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.1079 - val_loss: 0.1114\n",
      "Epoch 98/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.1075 - val_loss: 0.1111\n",
      "Epoch 99/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.1070 - val_loss: 0.1108\n",
      "Epoch 100/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.1066 - val_loss: 0.1105\n",
      "Epoch 101/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.1062 - val_loss: 0.1102\n",
      "Epoch 102/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.1057 - val_loss: 0.1099\n",
      "Epoch 103/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.1053 - val_loss: 0.1096\n",
      "Epoch 104/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.1049 - val_loss: 0.1093\n",
      "Epoch 105/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.1045 - val_loss: 0.1090\n",
      "Epoch 106/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.1041 - val_loss: 0.1087\n",
      "Epoch 107/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.1037 - val_loss: 0.1084\n",
      "Epoch 108/500\n",
      "1083/1083 [==============================] - 0s 117us/step - loss: 0.1033 - val_loss: 0.1081\n",
      "Epoch 109/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.1029 - val_loss: 0.1078\n",
      "Epoch 110/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.1025 - val_loss: 0.1075\n",
      "Epoch 111/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.1021 - val_loss: 0.1072\n",
      "Epoch 112/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.1018 - val_loss: 0.1070\n",
      "Epoch 113/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.1014 - val_loss: 0.1067\n",
      "Epoch 114/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.1010 - val_loss: 0.1064\n",
      "Epoch 115/500\n",
      "1083/1083 [==============================] - 0s 112us/step - loss: 0.1007 - val_loss: 0.1062\n",
      "Epoch 116/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.1004 - val_loss: 0.1059\n",
      "Epoch 117/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.1001 - val_loss: 0.1057\n",
      "Epoch 118/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.0997 - val_loss: 0.1054\n",
      "Epoch 119/500\n",
      "1083/1083 [==============================] - 0s 112us/step - loss: 0.0994 - val_loss: 0.1052\n",
      "Epoch 120/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0991 - val_loss: 0.1049\n",
      "Epoch 121/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0988 - val_loss: 0.1047\n",
      "Epoch 122/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0985 - val_loss: 0.1045\n",
      "Epoch 123/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0982 - val_loss: 0.1043\n",
      "Epoch 124/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0979 - val_loss: 0.1041\n",
      "Epoch 125/500\n",
      "1083/1083 [==============================] - 0s 149us/step - loss: 0.0976 - val_loss: 0.1039\n",
      "Epoch 126/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0974 - val_loss: 0.1036\n",
      "Epoch 127/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0971 - val_loss: 0.1034\n",
      "Epoch 128/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0968 - val_loss: 0.1032\n",
      "Epoch 129/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0965 - val_loss: 0.1030\n",
      "Epoch 130/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.0963 - val_loss: 0.1028\n",
      "Epoch 131/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0960 - val_loss: 0.1026\n",
      "Epoch 132/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.0958 - val_loss: 0.1024\n",
      "Epoch 133/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.0955 - val_loss: 0.1022\n",
      "Epoch 134/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0953 - val_loss: 0.1020\n",
      "Epoch 135/500\n",
      "1083/1083 [==============================] - 0s 141us/step - loss: 0.0950 - val_loss: 0.1019\n",
      "Epoch 136/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.0948 - val_loss: 0.1017\n",
      "Epoch 137/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0946 - val_loss: 0.1015\n",
      "Epoch 138/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0944 - val_loss: 0.1013\n",
      "Epoch 139/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0942 - val_loss: 0.1012\n",
      "Epoch 140/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0939 - val_loss: 0.1010\n",
      "Epoch 141/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0937 - val_loss: 0.1008\n",
      "Epoch 142/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0935 - val_loss: 0.1006\n",
      "Epoch 143/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0933 - val_loss: 0.1005\n",
      "Epoch 144/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0931 - val_loss: 0.1003\n",
      "Epoch 145/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0928 - val_loss: 0.1002\n",
      "Epoch 146/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0926 - val_loss: 0.1000\n",
      "Epoch 147/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0924 - val_loss: 0.0999\n",
      "Epoch 148/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0923 - val_loss: 0.0997\n",
      "Epoch 149/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0920 - val_loss: 0.0995\n",
      "Epoch 150/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.0918 - val_loss: 0.0994\n",
      "Epoch 151/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0916 - val_loss: 0.0992\n",
      "Epoch 152/500\n",
      "1083/1083 [==============================] - 0s 151us/step - loss: 0.0915 - val_loss: 0.0991\n",
      "Epoch 153/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0913 - val_loss: 0.0989\n",
      "Epoch 154/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0911 - val_loss: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0909 - val_loss: 0.0987\n",
      "Epoch 156/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.0907 - val_loss: 0.0985\n",
      "Epoch 157/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0906 - val_loss: 0.0984\n",
      "Epoch 158/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.0904 - val_loss: 0.0982\n",
      "Epoch 159/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.0902 - val_loss: 0.0981\n",
      "Epoch 160/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0901 - val_loss: 0.0980\n",
      "Epoch 161/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0899 - val_loss: 0.0978\n",
      "Epoch 162/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0897 - val_loss: 0.0977\n",
      "Epoch 163/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0895 - val_loss: 0.0975\n",
      "Epoch 164/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0894 - val_loss: 0.0974\n",
      "Epoch 165/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0892 - val_loss: 0.0972\n",
      "Epoch 166/500\n",
      "1083/1083 [==============================] - 0s 148us/step - loss: 0.0891 - val_loss: 0.0971\n",
      "Epoch 167/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0889 - val_loss: 0.0970\n",
      "Epoch 168/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0887 - val_loss: 0.0969\n",
      "Epoch 169/500\n",
      "1083/1083 [==============================] - 0s 150us/step - loss: 0.0885 - val_loss: 0.0967\n",
      "Epoch 170/500\n",
      "1083/1083 [==============================] - 0s 148us/step - loss: 0.0884 - val_loss: 0.0966\n",
      "Epoch 171/500\n",
      "1083/1083 [==============================] - 0s 159us/step - loss: 0.0882 - val_loss: 0.0965\n",
      "Epoch 172/500\n",
      "1083/1083 [==============================] - 0s 155us/step - loss: 0.0881 - val_loss: 0.0964\n",
      "Epoch 173/500\n",
      "1083/1083 [==============================] - 0s 153us/step - loss: 0.0879 - val_loss: 0.0962\n",
      "Epoch 174/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.0878 - val_loss: 0.0961\n",
      "Epoch 175/500\n",
      "1083/1083 [==============================] - 0s 150us/step - loss: 0.0876 - val_loss: 0.0960\n",
      "Epoch 176/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0875 - val_loss: 0.0959\n",
      "Epoch 177/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0873 - val_loss: 0.0958\n",
      "Epoch 178/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0872 - val_loss: 0.0957\n",
      "Epoch 179/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0870 - val_loss: 0.0956\n",
      "Epoch 180/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0869 - val_loss: 0.0954\n",
      "Epoch 181/500\n",
      "1083/1083 [==============================] - 0s 117us/step - loss: 0.0868 - val_loss: 0.0953\n",
      "Epoch 182/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0866 - val_loss: 0.0952\n",
      "Epoch 183/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0865 - val_loss: 0.0951\n",
      "Epoch 184/500\n",
      "1083/1083 [==============================] - 0s 112us/step - loss: 0.0863 - val_loss: 0.0950\n",
      "Epoch 185/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0862 - val_loss: 0.0949\n",
      "Epoch 186/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0861 - val_loss: 0.0948\n",
      "Epoch 187/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0859 - val_loss: 0.0947\n",
      "Epoch 188/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0858 - val_loss: 0.0946\n",
      "Epoch 189/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.0857 - val_loss: 0.0945\n",
      "Epoch 190/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0855 - val_loss: 0.0944\n",
      "Epoch 191/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.0854 - val_loss: 0.0943\n",
      "Epoch 192/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0853 - val_loss: 0.0942\n",
      "Epoch 193/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0851 - val_loss: 0.0941\n",
      "Epoch 194/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.0850 - val_loss: 0.0940\n",
      "Epoch 195/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0849 - val_loss: 0.0939\n",
      "Epoch 196/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0848 - val_loss: 0.0938\n",
      "Epoch 197/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0846 - val_loss: 0.0936\n",
      "Epoch 198/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0845 - val_loss: 0.0936\n",
      "Epoch 199/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0844 - val_loss: 0.0935\n",
      "Epoch 200/500\n",
      "1083/1083 [==============================] - 0s 203us/step - loss: 0.0843 - val_loss: 0.0934\n",
      "Epoch 201/500\n",
      "1083/1083 [==============================] - 0s 195us/step - loss: 0.0841 - val_loss: 0.0933\n",
      "Epoch 202/500\n",
      "1083/1083 [==============================] - 0s 195us/step - loss: 0.0840 - val_loss: 0.0932\n",
      "Epoch 203/500\n",
      "1083/1083 [==============================] - 0s 149us/step - loss: 0.0839 - val_loss: 0.0931\n",
      "Epoch 204/500\n",
      "1083/1083 [==============================] - 0s 151us/step - loss: 0.0838 - val_loss: 0.0930\n",
      "Epoch 205/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0836 - val_loss: 0.0929\n",
      "Epoch 206/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0835 - val_loss: 0.0929\n",
      "Epoch 207/500\n",
      "1083/1083 [==============================] - 0s 114us/step - loss: 0.0834 - val_loss: 0.0928\n",
      "Epoch 208/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0833 - val_loss: 0.0927\n",
      "Epoch 209/500\n",
      "1083/1083 [==============================] - 0s 117us/step - loss: 0.0832 - val_loss: 0.0926\n",
      "Epoch 210/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0831 - val_loss: 0.0925\n",
      "Epoch 211/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0829 - val_loss: 0.0924\n",
      "Epoch 212/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0828 - val_loss: 0.0923\n",
      "Epoch 213/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0827 - val_loss: 0.0922\n",
      "Epoch 214/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0826 - val_loss: 0.0922\n",
      "Epoch 215/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0825 - val_loss: 0.0921\n",
      "Epoch 216/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.0824 - val_loss: 0.0920\n",
      "Epoch 217/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0823 - val_loss: 0.0919\n",
      "Epoch 218/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0822 - val_loss: 0.0918\n",
      "Epoch 219/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0821 - val_loss: 0.0918\n",
      "Epoch 220/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0820 - val_loss: 0.0917\n",
      "Epoch 221/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0819 - val_loss: 0.0916\n",
      "Epoch 222/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0818 - val_loss: 0.0916\n",
      "Epoch 223/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0816 - val_loss: 0.0915\n",
      "Epoch 224/500\n",
      "1083/1083 [==============================] - 0s 117us/step - loss: 0.0815 - val_loss: 0.0914\n",
      "Epoch 225/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0814 - val_loss: 0.0913\n",
      "Epoch 226/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0813 - val_loss: 0.0913\n",
      "Epoch 227/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0812 - val_loss: 0.0912\n",
      "Epoch 228/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0811 - val_loss: 0.0911\n",
      "Epoch 229/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0810 - val_loss: 0.0910\n",
      "Epoch 230/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0809 - val_loss: 0.0910\n",
      "Epoch 231/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0808 - val_loss: 0.0909\n",
      "Epoch 232/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0807 - val_loss: 0.0908\n",
      "Epoch 233/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0806 - val_loss: 0.0908\n",
      "Epoch 234/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0805 - val_loss: 0.0907\n",
      "Epoch 235/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0805 - val_loss: 0.0906\n",
      "Epoch 236/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0803 - val_loss: 0.0906\n",
      "Epoch 237/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0802 - val_loss: 0.0905\n",
      "Epoch 238/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0802 - val_loss: 0.0904\n",
      "Epoch 239/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0801 - val_loss: 0.0904\n",
      "Epoch 240/500\n",
      "1083/1083 [==============================] - 0s 111us/step - loss: 0.0800 - val_loss: 0.0903\n",
      "Epoch 241/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.0799 - val_loss: 0.0903\n",
      "Epoch 242/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0798 - val_loss: 0.0902\n",
      "Epoch 243/500\n",
      "1083/1083 [==============================] - 0s 114us/step - loss: 0.0797 - val_loss: 0.0901\n",
      "Epoch 244/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0796 - val_loss: 0.0901\n",
      "Epoch 245/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0795 - val_loss: 0.0900\n",
      "Epoch 246/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0794 - val_loss: 0.0900\n",
      "Epoch 247/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.0793 - val_loss: 0.0899\n",
      "Epoch 248/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0792 - val_loss: 0.0898\n",
      "Epoch 249/500\n",
      "1083/1083 [==============================] - 0s 150us/step - loss: 0.0791 - val_loss: 0.0898\n",
      "Epoch 250/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0791 - val_loss: 0.0897\n",
      "Epoch 251/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0790 - val_loss: 0.0897\n",
      "Epoch 252/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0789 - val_loss: 0.0896\n",
      "Epoch 253/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0788 - val_loss: 0.0895\n",
      "Epoch 254/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0787 - val_loss: 0.0895\n",
      "Epoch 255/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0786 - val_loss: 0.0894\n",
      "Epoch 256/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0786 - val_loss: 0.0894\n",
      "Epoch 257/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0784 - val_loss: 0.0893\n",
      "Epoch 258/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0784 - val_loss: 0.0893\n",
      "Epoch 259/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0783 - val_loss: 0.0893\n",
      "Epoch 260/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0782 - val_loss: 0.0892\n",
      "Epoch 261/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0781 - val_loss: 0.0892\n",
      "Epoch 262/500\n",
      "1083/1083 [==============================] - 0s 114us/step - loss: 0.0780 - val_loss: 0.0891\n",
      "Epoch 263/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0779 - val_loss: 0.0891\n",
      "Epoch 264/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0779 - val_loss: 0.0890\n",
      "Epoch 265/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0778 - val_loss: 0.0890\n",
      "Epoch 266/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0777 - val_loss: 0.0889\n",
      "Epoch 267/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0776 - val_loss: 0.0888\n",
      "Epoch 268/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0775 - val_loss: 0.0888\n",
      "Epoch 269/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0775 - val_loss: 0.0888\n",
      "Epoch 270/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0774 - val_loss: 0.0887\n",
      "Epoch 271/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0773 - val_loss: 0.0887\n",
      "Epoch 272/500\n",
      "1083/1083 [==============================] - 0s 145us/step - loss: 0.0772 - val_loss: 0.0886\n",
      "Epoch 273/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0772 - val_loss: 0.0886\n",
      "Epoch 274/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0771 - val_loss: 0.0885\n",
      "Epoch 275/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0770 - val_loss: 0.0885\n",
      "Epoch 276/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.0769 - val_loss: 0.0884\n",
      "Epoch 277/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0768 - val_loss: 0.0884\n",
      "Epoch 278/500\n",
      "1083/1083 [==============================] - 0s 156us/step - loss: 0.0768 - val_loss: 0.0883\n",
      "Epoch 279/500\n",
      "1083/1083 [==============================] - 0s 144us/step - loss: 0.0767 - val_loss: 0.0883\n",
      "Epoch 280/500\n",
      "1083/1083 [==============================] - 0s 166us/step - loss: 0.0766 - val_loss: 0.0882\n",
      "Epoch 281/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.0765 - val_loss: 0.0882\n",
      "Epoch 282/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0765 - val_loss: 0.0882\n",
      "Epoch 283/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0764 - val_loss: 0.0881\n",
      "Epoch 284/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0763 - val_loss: 0.0881\n",
      "Epoch 285/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0763 - val_loss: 0.0880\n",
      "Epoch 286/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0762 - val_loss: 0.0880\n",
      "Epoch 287/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0761 - val_loss: 0.0879\n",
      "Epoch 288/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0760 - val_loss: 0.0879\n",
      "Epoch 289/500\n",
      "1083/1083 [==============================] - 0s 144us/step - loss: 0.0760 - val_loss: 0.0879\n",
      "Epoch 290/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0759 - val_loss: 0.0878\n",
      "Epoch 291/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0758 - val_loss: 0.0878\n",
      "Epoch 292/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0758 - val_loss: 0.0878\n",
      "Epoch 293/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0757 - val_loss: 0.0877\n",
      "Epoch 294/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0756 - val_loss: 0.0877\n",
      "Epoch 295/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0755 - val_loss: 0.0876\n",
      "Epoch 296/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0754 - val_loss: 0.0876\n",
      "Epoch 297/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0754 - val_loss: 0.0876\n",
      "Epoch 298/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0753 - val_loss: 0.0875\n",
      "Epoch 299/500\n",
      "1083/1083 [==============================] - 0s 149us/step - loss: 0.0753 - val_loss: 0.0875\n",
      "Epoch 300/500\n",
      "1083/1083 [==============================] - 0s 168us/step - loss: 0.0752 - val_loss: 0.0874\n",
      "Epoch 301/500\n",
      "1083/1083 [==============================] - 0s 186us/step - loss: 0.0751 - val_loss: 0.0874\n",
      "Epoch 302/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0750 - val_loss: 0.0874\n",
      "Epoch 303/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0750 - val_loss: 0.0874\n",
      "Epoch 304/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.0749 - val_loss: 0.0873\n",
      "Epoch 305/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.0748 - val_loss: 0.0873\n",
      "Epoch 306/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0748 - val_loss: 0.0873\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0747 - val_loss: 0.0872\n",
      "Epoch 308/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0746 - val_loss: 0.0872\n",
      "Epoch 309/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0746 - val_loss: 0.0871\n",
      "Epoch 310/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0745 - val_loss: 0.0871\n",
      "Epoch 311/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0744 - val_loss: 0.0871\n",
      "Epoch 312/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0744 - val_loss: 0.0870\n",
      "Epoch 313/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0743 - val_loss: 0.0870\n",
      "Epoch 314/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0742 - val_loss: 0.0870\n",
      "Epoch 315/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0742 - val_loss: 0.0870\n",
      "Epoch 316/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0741 - val_loss: 0.0869\n",
      "Epoch 317/500\n",
      "1083/1083 [==============================] - 0s 165us/step - loss: 0.0741 - val_loss: 0.0869\n",
      "Epoch 318/500\n",
      "1083/1083 [==============================] - 0s 187us/step - loss: 0.0740 - val_loss: 0.0869\n",
      "Epoch 319/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0740 - val_loss: 0.0868\n",
      "Epoch 320/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0739 - val_loss: 0.0868\n",
      "Epoch 321/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0738 - val_loss: 0.0868\n",
      "Epoch 322/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0738 - val_loss: 0.0868\n",
      "Epoch 323/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0737 - val_loss: 0.0867\n",
      "Epoch 324/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.0736 - val_loss: 0.0867\n",
      "Epoch 325/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0735 - val_loss: 0.0867\n",
      "Epoch 326/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0735 - val_loss: 0.0866\n",
      "Epoch 327/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0735 - val_loss: 0.0866\n",
      "Epoch 328/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0734 - val_loss: 0.0866\n",
      "Epoch 329/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0733 - val_loss: 0.0866\n",
      "Epoch 330/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.0732 - val_loss: 0.0865\n",
      "Epoch 331/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0732 - val_loss: 0.0865\n",
      "Epoch 332/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0731 - val_loss: 0.0865\n",
      "Epoch 333/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.0731 - val_loss: 0.0865\n",
      "Epoch 334/500\n",
      "1083/1083 [==============================] - 0s 141us/step - loss: 0.0730 - val_loss: 0.0864\n",
      "Epoch 335/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0730 - val_loss: 0.0864\n",
      "Epoch 336/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0729 - val_loss: 0.0864\n",
      "Epoch 337/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0728 - val_loss: 0.0863\n",
      "Epoch 338/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0728 - val_loss: 0.0863\n",
      "Epoch 339/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0727 - val_loss: 0.0863\n",
      "Epoch 340/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0727 - val_loss: 0.0863\n",
      "Epoch 341/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0726 - val_loss: 0.0862\n",
      "Epoch 342/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0725 - val_loss: 0.0862\n",
      "Epoch 343/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0725 - val_loss: 0.0862\n",
      "Epoch 344/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0724 - val_loss: 0.0862\n",
      "Epoch 345/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0724 - val_loss: 0.0861\n",
      "Epoch 346/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0723 - val_loss: 0.0861\n",
      "Epoch 347/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0723 - val_loss: 0.0861\n",
      "Epoch 348/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0722 - val_loss: 0.0861\n",
      "Epoch 349/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.0721 - val_loss: 0.0860\n",
      "Epoch 350/500\n",
      "1083/1083 [==============================] - 0s 152us/step - loss: 0.0721 - val_loss: 0.0860\n",
      "Epoch 351/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0720 - val_loss: 0.0860\n",
      "Epoch 352/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.0720 - val_loss: 0.0860\n",
      "Epoch 353/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0719 - val_loss: 0.0860\n",
      "Epoch 354/500\n",
      "1083/1083 [==============================] - 0s 114us/step - loss: 0.0718 - val_loss: 0.0859\n",
      "Epoch 355/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0718 - val_loss: 0.0859\n",
      "Epoch 356/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0718 - val_loss: 0.0859\n",
      "Epoch 357/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0717 - val_loss: 0.0859\n",
      "Epoch 358/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0716 - val_loss: 0.0858\n",
      "Epoch 359/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0716 - val_loss: 0.0858\n",
      "Epoch 360/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0715 - val_loss: 0.0858\n",
      "Epoch 361/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.0715 - val_loss: 0.0857\n",
      "Epoch 362/500\n",
      "1083/1083 [==============================] - 0s 137us/step - loss: 0.0714 - val_loss: 0.0857\n",
      "Epoch 363/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0713 - val_loss: 0.0857\n",
      "Epoch 364/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0713 - val_loss: 0.0857\n",
      "Epoch 365/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0713 - val_loss: 0.0856\n",
      "Epoch 366/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0712 - val_loss: 0.0856\n",
      "Epoch 367/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0711 - val_loss: 0.0856\n",
      "Epoch 368/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0711 - val_loss: 0.0856\n",
      "Epoch 369/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0711 - val_loss: 0.0856\n",
      "Epoch 370/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0710 - val_loss: 0.0856\n",
      "Epoch 371/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0710 - val_loss: 0.0855\n",
      "Epoch 372/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0709 - val_loss: 0.0855\n",
      "Epoch 373/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0708 - val_loss: 0.0855\n",
      "Epoch 374/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0708 - val_loss: 0.0855\n",
      "Epoch 375/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.0707 - val_loss: 0.0855\n",
      "Epoch 376/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.0707 - val_loss: 0.0854\n",
      "Epoch 377/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0706 - val_loss: 0.0854\n",
      "Epoch 378/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0706 - val_loss: 0.0854\n",
      "Epoch 379/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0705 - val_loss: 0.0854\n",
      "Epoch 380/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0705 - val_loss: 0.0854\n",
      "Epoch 381/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0704 - val_loss: 0.0854\n",
      "Epoch 382/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0704 - val_loss: 0.0854\n",
      "Epoch 383/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0703 - val_loss: 0.0853\n",
      "Epoch 384/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0703 - val_loss: 0.0853\n",
      "Epoch 385/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0702 - val_loss: 0.0853\n",
      "Epoch 386/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0701 - val_loss: 0.0853\n",
      "Epoch 387/500\n",
      "1083/1083 [==============================] - 0s 112us/step - loss: 0.0701 - val_loss: 0.0852\n",
      "Epoch 388/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0701 - val_loss: 0.0852\n",
      "Epoch 389/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0700 - val_loss: 0.0852\n",
      "Epoch 390/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0700 - val_loss: 0.0852\n",
      "Epoch 391/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0699 - val_loss: 0.0852\n",
      "Epoch 392/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0699 - val_loss: 0.0852\n",
      "Epoch 393/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0698 - val_loss: 0.0851\n",
      "Epoch 394/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0698 - val_loss: 0.0851\n",
      "Epoch 395/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0697 - val_loss: 0.0851\n",
      "Epoch 396/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0697 - val_loss: 0.0851\n",
      "Epoch 397/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0696 - val_loss: 0.0851\n",
      "Epoch 398/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0695 - val_loss: 0.0850\n",
      "Epoch 399/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0695 - val_loss: 0.0850\n",
      "Epoch 400/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0695 - val_loss: 0.0850\n",
      "Epoch 401/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0694 - val_loss: 0.0850\n",
      "Epoch 402/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0694 - val_loss: 0.0850\n",
      "Epoch 403/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0693 - val_loss: 0.0849\n",
      "Epoch 404/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.0693 - val_loss: 0.0849\n",
      "Epoch 405/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0692 - val_loss: 0.0849\n",
      "Epoch 406/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0692 - val_loss: 0.0849\n",
      "Epoch 407/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0691 - val_loss: 0.0849\n",
      "Epoch 408/500\n",
      "1083/1083 [==============================] - 0s 124us/step - loss: 0.0691 - val_loss: 0.0849\n",
      "Epoch 409/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0690 - val_loss: 0.0849\n",
      "Epoch 410/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0690 - val_loss: 0.0848\n",
      "Epoch 411/500\n",
      "1083/1083 [==============================] - 0s 144us/step - loss: 0.0689 - val_loss: 0.0848\n",
      "Epoch 412/500\n",
      "1083/1083 [==============================] - 0s 141us/step - loss: 0.0689 - val_loss: 0.0848\n",
      "Epoch 413/500\n",
      "1083/1083 [==============================] - 0s 140us/step - loss: 0.0688 - val_loss: 0.0848\n",
      "Epoch 414/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0688 - val_loss: 0.0848\n",
      "Epoch 415/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0687 - val_loss: 0.0848\n",
      "Epoch 416/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0687 - val_loss: 0.0848\n",
      "Epoch 417/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.0686 - val_loss: 0.0848\n",
      "Epoch 418/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0686 - val_loss: 0.0847\n",
      "Epoch 419/500\n",
      "1083/1083 [==============================] - 0s 147us/step - loss: 0.0685 - val_loss: 0.0847\n",
      "Epoch 420/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0685 - val_loss: 0.0847\n",
      "Epoch 421/500\n",
      "1083/1083 [==============================] - 0s 143us/step - loss: 0.0684 - val_loss: 0.0847\n",
      "Epoch 422/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0684 - val_loss: 0.0847\n",
      "Epoch 423/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0684 - val_loss: 0.0847\n",
      "Epoch 424/500\n",
      "1083/1083 [==============================] - 0s 139us/step - loss: 0.0683 - val_loss: 0.0847\n",
      "Epoch 425/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0683 - val_loss: 0.0847\n",
      "Epoch 426/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0682 - val_loss: 0.0847\n",
      "Epoch 427/500\n",
      "1083/1083 [==============================] - 0s 110us/step - loss: 0.0682 - val_loss: 0.0847\n",
      "Epoch 428/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0681 - val_loss: 0.0847\n",
      "Epoch 429/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0681 - val_loss: 0.0846\n",
      "Epoch 430/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0680 - val_loss: 0.0847\n",
      "Epoch 431/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0680 - val_loss: 0.0846\n",
      "Epoch 432/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0680 - val_loss: 0.0846\n",
      "Epoch 433/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0679 - val_loss: 0.0846\n",
      "Epoch 434/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0679 - val_loss: 0.0846\n",
      "Epoch 435/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0678 - val_loss: 0.0846\n",
      "Epoch 436/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0677 - val_loss: 0.0846\n",
      "Epoch 437/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0677 - val_loss: 0.0846\n",
      "Epoch 438/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0677 - val_loss: 0.0846\n",
      "Epoch 439/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0676 - val_loss: 0.0846\n",
      "Epoch 440/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0676 - val_loss: 0.0845\n",
      "Epoch 441/500\n",
      "1083/1083 [==============================] - 0s 126us/step - loss: 0.0675 - val_loss: 0.0845\n",
      "Epoch 442/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0675 - val_loss: 0.0845\n",
      "Epoch 443/500\n",
      "1083/1083 [==============================] - 0s 138us/step - loss: 0.0675 - val_loss: 0.0845\n",
      "Epoch 444/500\n",
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0674 - val_loss: 0.0845\n",
      "Epoch 445/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0674 - val_loss: 0.0845\n",
      "Epoch 446/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0673 - val_loss: 0.0845\n",
      "Epoch 447/500\n",
      "1083/1083 [==============================] - 0s 129us/step - loss: 0.0673 - val_loss: 0.0844\n",
      "Epoch 448/500\n",
      "1083/1083 [==============================] - 0s 141us/step - loss: 0.0672 - val_loss: 0.0844\n",
      "Epoch 449/500\n",
      "1083/1083 [==============================] - 0s 189us/step - loss: 0.0672 - val_loss: 0.0844\n",
      "Epoch 450/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.0671 - val_loss: 0.0844\n",
      "Epoch 451/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0671 - val_loss: 0.0844\n",
      "Epoch 452/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0671 - val_loss: 0.0844\n",
      "Epoch 453/500\n",
      "1083/1083 [==============================] - 0s 134us/step - loss: 0.0670 - val_loss: 0.0844\n",
      "Epoch 454/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0670 - val_loss: 0.0844\n",
      "Epoch 455/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0669 - val_loss: 0.0844\n",
      "Epoch 456/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0669 - val_loss: 0.0843\n",
      "Epoch 457/500\n",
      "1083/1083 [==============================] - 0s 128us/step - loss: 0.0669 - val_loss: 0.0843\n",
      "Epoch 458/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0668 - val_loss: 0.0844\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083/1083 [==============================] - 0s 132us/step - loss: 0.0668 - val_loss: 0.0844\n",
      "Epoch 460/500\n",
      "1083/1083 [==============================] - 0s 123us/step - loss: 0.0667 - val_loss: 0.0843\n",
      "Epoch 461/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0667 - val_loss: 0.0843\n",
      "Epoch 462/500\n",
      "1083/1083 [==============================] - 0s 125us/step - loss: 0.0666 - val_loss: 0.0843\n",
      "Epoch 463/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0666 - val_loss: 0.0843\n",
      "Epoch 464/500\n",
      "1083/1083 [==============================] - 0s 115us/step - loss: 0.0665 - val_loss: 0.0843\n",
      "Epoch 465/500\n",
      "1083/1083 [==============================] - 0s 113us/step - loss: 0.0665 - val_loss: 0.0843\n",
      "Epoch 466/500\n",
      "1083/1083 [==============================] - 0s 112us/step - loss: 0.0665 - val_loss: 0.0843\n",
      "Epoch 467/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0664 - val_loss: 0.0843\n",
      "Epoch 468/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0664 - val_loss: 0.0843\n",
      "Epoch 469/500\n",
      "1083/1083 [==============================] - 0s 146us/step - loss: 0.0663 - val_loss: 0.0843\n",
      "Epoch 470/500\n",
      "1083/1083 [==============================] - 0s 135us/step - loss: 0.0663 - val_loss: 0.0842\n",
      "Epoch 471/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0662 - val_loss: 0.0842\n",
      "Epoch 472/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0662 - val_loss: 0.0842\n",
      "Epoch 473/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0662 - val_loss: 0.0842\n",
      "Epoch 474/500\n",
      "1083/1083 [==============================] - 0s 133us/step - loss: 0.0661 - val_loss: 0.0843\n",
      "Epoch 475/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0661 - val_loss: 0.0843\n",
      "Epoch 476/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0660 - val_loss: 0.0842\n",
      "Epoch 477/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0660 - val_loss: 0.0842\n",
      "Epoch 478/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0660 - val_loss: 0.0842\n",
      "Epoch 479/500\n",
      "1083/1083 [==============================] - 0s 142us/step - loss: 0.0659 - val_loss: 0.0842\n",
      "Epoch 480/500\n",
      "1083/1083 [==============================] - 0s 121us/step - loss: 0.0658 - val_loss: 0.0842\n",
      "Epoch 481/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0658 - val_loss: 0.0842\n",
      "Epoch 482/500\n",
      "1083/1083 [==============================] - 0s 127us/step - loss: 0.0658 - val_loss: 0.0842\n",
      "Epoch 483/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0657 - val_loss: 0.0842\n",
      "Epoch 484/500\n",
      "1083/1083 [==============================] - 0s 119us/step - loss: 0.0657 - val_loss: 0.0842\n",
      "Epoch 485/500\n",
      "1083/1083 [==============================] - 0s 158us/step - loss: 0.0657 - val_loss: 0.0841\n",
      "Epoch 486/500\n",
      "1083/1083 [==============================] - 0s 136us/step - loss: 0.0656 - val_loss: 0.0841\n",
      "Epoch 487/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0656 - val_loss: 0.0841\n",
      "Epoch 488/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0655 - val_loss: 0.0841\n",
      "Epoch 489/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0655 - val_loss: 0.0841\n",
      "Epoch 490/500\n",
      "1083/1083 [==============================] - 0s 122us/step - loss: 0.0655 - val_loss: 0.0841\n",
      "Epoch 491/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0654 - val_loss: 0.0841\n",
      "Epoch 492/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0654 - val_loss: 0.0841\n",
      "Epoch 493/500\n",
      "1083/1083 [==============================] - 0s 114us/step - loss: 0.0653 - val_loss: 0.0841\n",
      "Epoch 494/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0653 - val_loss: 0.0841\n",
      "Epoch 495/500\n",
      "1083/1083 [==============================] - 0s 118us/step - loss: 0.0652 - val_loss: 0.0841\n",
      "Epoch 496/500\n",
      "1083/1083 [==============================] - 0s 131us/step - loss: 0.0652 - val_loss: 0.0841\n",
      "Epoch 497/500\n",
      "1083/1083 [==============================] - 0s 116us/step - loss: 0.0652 - val_loss: 0.0841\n",
      "Epoch 498/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0651 - val_loss: 0.0841\n",
      "Epoch 499/500\n",
      "1083/1083 [==============================] - 0s 130us/step - loss: 0.0651 - val_loss: 0.0841\n",
      "Epoch 500/500\n",
      "1083/1083 [==============================] - 0s 120us/step - loss: 0.0650 - val_loss: 0.0841\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train_log_scaled, validation_data=(X_val_scaled,y_val_log_scaled), epochs=500, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXwc9Z3n/9enWy21TuuWLZ8yNgabEMxpApkomWQGyAxkfmETWHIuO+wcyQQmsxOyk82wDLOTnd9kkp3HkkngkUAOAiEkJAzLkYSgeAinDTYY37fl2zpsybq7v/tHldSldktu2Wq1Wv1+Ph796KpvfavqU9+W+tP1rcucc4iISP4KZTsAERHJLiUCEZE8p0QgIpLnlAhERPKcEoGISJ5TIhARyXNKBDOEmS0yM2dmBWnU/ZSZvTAVcfnr+yMz22dm3Wa2cqrWO52YWbOZtWY7DpjY38p0ZWZPm9knJ7tuvlIiyAIz221mA2ZWm1S+zv8HXZSdyDLmn4DPOOfKnHNvZDuYqeB/jkuyHcdUM7MHzeye09Q567Zxzl3rnPvuZNfNV0oE2bMLuHl4xMzeARRnL5zJF/jFuRB4+wyXEZ68iHJHvm43jPq7kSmiRJA93wc+ERj/JPC9YAUzm2Vm3zOzo2a2x8y+ZGYhf1rYzP7JzI6Z2U7ggynm/baZHTSz/WZ2TzpfLoFug9vM7IA//+cD00NmdqeZ7TCzNjN71Myqk+a91cz2Av9uZt1AGFhvZjv8euebWYuZdZrZ22Z2fWD5D5rZv5rZU2Z2EnivX/YNfxe/28x+a2azzezrZtZhZpuDXU6B+LrMbKOZ/VFg2qfM7AW/7TrMbJeZXRuYXm1mD/jb3mFmPwtM+wN/r63TzF40swvHaMPV/uB6P96PBqZ93syO+O366dNs93if/11m9oMUn1uBP95kZqv9NviVmd0brO+7xcz2+n9DfxNYVpHftgf819fNrCjYfknb68xsiZndBtwC/LW/3f+WTtuY321mZl8ws0PAA2ZWZWZP+tve4Q/PCyynxcz+c5qf6UTqptNuM49zTq8pfgG7gfcDW4Dz8b4o9+H9cnbAIr/e94CfA+XAImArcKs/7U+AzcB8oBp43p+3wJ/+M+BbQClQD7wK/Bd/2qeAF8aIbZG/nIf9ed8BHAXe70+/HXgZmAcU+et4OGne7/nzFvvlDljiD0eA7cB/AwqB9wFdwDJ/+oPAceAqvB8qUb/sGHCJP/5rvD2qT/htdw/wfGAb/gPQ6M//UeAkMCew7YPAH/vz/ilwADB/+v8FfgRU+bG+xy+/GDgCXOHP90n/cywaox1HttkfbwaGgLv95V4H9ABV42z3eJ//XcAPUnxuw5//S3hdcoXA1cCJ4fqBuvfj7YW+E+gHzven3+1/xvVAHfAi8Hdj/e0kfb4PAvec5u9/rLb5X3h/U8VADfBhoMTf/h8DPwvM0wL85zQ/04nUHbPdZvIr6wHk44tEIvgS8A/ANcAvgQL/n2SR/0faDywPzPdfgBZ/+NfAnwSm/d7wFwHQ4M9bHJh+M/6XZap/5kC94S+J8wJl/wh82x/eBPxuYNoc/x+rIDDv4qRlBr8o3g0cAkKB6Q8Dd/nDDwLfS5r/QeD+wPhngU2B8XcAneO09zrghsC2bw9MK/Hjm+1vSxz/yzlpGf+K/2UYKNuCnyhS1E/1ZdeL/0Xtlx0BVqXa7jQ+/7sYIxEAC/C+WEsC03/AqYlgXmD6q8BN/vAO4LrAtN8Hdo/1t8PkJIIBIDrOPBcBHYHxFkZ/uaf8TCdS93TtNpNf6ovLru8Dq4EmkrqFgFq8XyV7AmV7gLn+cCPeXkRw2rCFeL86D5rZcFkoqf7pJC/7HYFlP25m8cD0GF7ySTVvskZgn3MuOH9wu8aa/3BguDfFeNnwiJl9AvhLvC88/GnBA/OHhgeccz1+G5Xh7Vm1O+c6Uqx/IfBJM/tsoKzQ3550tTnnhgLjPcG4Gb3dp/v8x9OItx09Scuen1TvUGA4GEtjivVOZDvPxFHnXN/wiJmVAF/D+5FU5ReXm1nYORdLMf9Yn2kqY9WtJb12m3F0jCCLnHN78Lo4rgN+mjT5GN4v7YWBsgXAfn/4IKP/QBcEhvfh/Zqsdc5V+q8K59yKCYSXvOwDgWVfG1hupXMu6pzbH6g/3i1tDwDzh/u6U2zX6eYfl5ktxOvy+AxQ45yrBDYANu6Mnn1AtZlVjjHt75O2u8Q59/CZxppCcLtP9/mfxPs1O2x2YPgg3nYEp0/ky+xAivUOf/6j1mtmwfXCmX92yfN9HlgGXOGcqwB+Z3iVZ7j8dJxtu+UsJYLsuxV4n3PuZLDQ/9XzKPD3Zlbuf8H9Jd6uKv60vzCzeWZWBdwZmPcg8Avgq2ZWYd4B3nPM7D0TiOu/m1mJma0APo3Xbw7wTT+mhQBmVmdmN0xgua/gfZn8tZlFzKwZ+EPgkQksYzyleF8qR/34Pg1ckM6Mfrs9DXzDP1gZMbPhL6D7gT8xsyvMU2pmHzSz8jEWdxhYfKYbkcbnvw74HTNbYGazgC8G5t0DrAHuMrNCM7sSr43T9TDwJf+zrQW+HFjvemCFmV1kZlG8LqqgdLY7nTrleHt6neadjPC3E4j/jExCu+UsJYIsc87tcM6tGWPyZ/G+NHcCLwA/BL7jT7sfeBbvH/N1Tt2j+ARe18JGoAN4DK8PPF2/wTuo+xzwT865X/jl/xt4AviFmXXhHVS8It2FOucGgOuBa/F+9X4D+IRzbvMEYhtv+RuBr+Id9DuM16X12wks4uN4v8Q34/Xh3+4vdw3eAcb/g9ee2/H6m8dyF/Bd884w+siENiJhzM/fOfdLvOT8JrAWeDJp3luAK4E2vIPpP8LbS0zHPXhfiG8Cb+H9fd3jr3cr3sHkXwHb/LiCvg0s97f7Z6R2F6dvm6/jHTQ+hvc39kyasZ+ts2m3nDV8pFwE8E5DxOuuiiT1Z0sOM7MfAZudcxn/ZT2T5Eu7aY9AZAYys8v87sCQmV0D3IB3SrGMI1/bTWcNicxMs/G6C2uAVuBPXZ7c3uMs5WW7qWtIRCTPqWtIRCTP5VzXUGVlpVuyJO9u6pjSyZMnKS0tzXYY04LaIkFtkaC2SFi7du0x51xdqmk5lwgaGhpYs2assy3zS0tLC83NzdkOY1pQWySoLRLUFglmtmesaeoaEhHJc0oEIiJ5TolARCTPZewYgZl9B/gD4Ihz7pR7vZh3y7//TeK+7J9yzr2eqXhEJL8NDg7S2tpKX1/f6SvnsGg0yrx584hEImnPk8mDxQ/i3Zcl+fbKw64FlvqvK/Du9572PWtERCaitbWV8vJyFi1aROD27DOKc462tjZaW1tpampKe76MdQ0551YD7eNUuQHvQRzOOfcyUGlmE7kpmohI2vr6+qipqZmxSQDAzKipqZnwXk82Tx+dy+gHcbT6ZQeTK/rPQr0NoK6ujpaWlqmIb9rr7u5WW/jUFglqi4RgW8yaNYvu7u7sBjRF+vr6JvQ3kM1EkCotp7zfhXPuPuA+gHcsnu10XrBH50gnqC0S1BYJwbbYtGkT5eVjPT5iZolGo6xcuTLt+tk8a6iV0U//mUfiKUhjKuzvAN0fSURyTGdnJ9/4xjcmPN91111HZ2dnBiJKyGYieAL4hP+0p1XAcf8JUeMyNwQduzIfnYjIJBorEcRiqR7BnPDUU09RWZnq6amTJ5Onjz4MNAO1ZtaK96i5CIBz7pvAU3injm7HO33002kvfO8rUH3GTwEUEZlyd955Jzt27OCiiy4iEolQVlbGnDlzWLduHRs3buRDH/oQ+/bto6+vj8997nPcdtttACxatIg1a9bQ3d3Ntddey9VXX82LL77I3Llz+fnPf05xcfFZx5axROCcu/k00x3w5xNeroVh70tw0biLFxEZ0//4t7fZeODEpC5zeWMFf/uHK8ac/pWvfIUNGzawbt06Wlpa+OAHP8iGDRtGTvP8zne+Q3V1Nb29vVx22WV8+MMfpqamZtQytm3bxsMPP8z999/PRz7yEX7yk5/wsY997Kxjz7mbzsXCUdj3SrbDEBE5K5dffvmoc/3/5V/+hccffxyAffv2sW3btlMSQVNTExdddBEAl1xyCbt3756UWHIzERzdDD3tUFKd7XBEJAeN98t9qgRvj93S0sKvfvUrXnrpJUpKSmhubk55LUBRUdHIcDgcpre3d1Jiybl7DcXCUW9AewUikkPKy8vp6upKOe348eNUVVVRUlLC5s2befnll6c0tpzbI4iHoxDuhd0vwLJrsx2OiEhaampquOqqq7jgggsoLi6moaFhZNo111zDN7/5TS688EKWLVvGqlWrpjS2nEsEDoO5l8KeF7MdiojIhPzwhz9MWV5UVMTTTz+dctrwcYDa2lo2bNgwUv5Xf/VXkxZXznUNAbDwXXBwPfSn3s0SEZH05WYiWHQVuJiOE4iITILcTATzLgcLq3tIRGQS5GYiKCqDxpVKBCIikyA3EwF4xwn2r4XByTmPVkQkX+VwIrgKYgPQuibbkYiI5LTcTQQLVgGm7iERmZHKysqmbF25mwiKK2H2BbDnhWxHIiKS03LugrJR5q+CdT+EeAxC4WxHIyIypi984QssXLiQP/uzPwPgrrvuwsxYvXo1HR0dDA4Ocs8993DDDTdMeWy5nQjmXgyv3Q/HtkL9+dmORkRyxdN3wqG3JneZs98B135lzMk33XQTt99++0giePTRR3nmmWe44447qKio4NixY6xatYrrr78es1RP8s2cnEsEnf2Bx1Q2Xuy9739diUBEprWVK1dy5MgRDhw4wNGjR6mqqmLOnDnccccdrF69mlAoxP79+zl8+DCzZ8+e0thyLhGc6HcMxeIUhENQuxQKy+DA67DylmyHJiK5Ypxf7pl044038thjj3Ho0CFuuukmHnroIY4ePcratWuJRCIsWrQo5e2nMy3nDhbHgfWt/oOcQ2GYc5G3RyAiMs3ddNNNPPLIIzz22GPceOONHD9+nPr6eiKRCM8//zx79uzJSlw5lwgAVm89lhiZuxIOb4ChgewFJCKShhUrVtDV1cXcuXOZM2cOt9xyC2vWrOHSSy/loYce4rzzzstKXDnXNVQUhtXbjnLHB871Chov9i4sO7zBO3gsIjKNvfVW4iB1bW0tL730Usp63d3dUxVS7u0RFBcY6/d1crxn0CsY/vI/oO4hEZEzkZOJIO7gxR1+91DlQiiuhv1vZDcwEZEclXOJoDAM5UUFrN521Csw8/YKtEcgIqfhnDt9pRx3JtuYc4nAgCvPqWH11mOJDZ59oXdRmQ4Yi8gYotEobW1tMzoZOOdoa2sjGo1OaL6cO1gM8O6ltfxi42F2t/XQVFsKDSsgPuQlg9kXZDs8EZmG5s2bR2trK0ePHs12KBkVjUaZN2/ehObJyURw9dI6AF7YfsxLBPXLvQlHNioRiEhKkUiEpqambIcxLeVc1xDAopoS5lYW88LwcYLapRCKwOG3sxuYiEgOyslEYGZcvaSWF3e0MRSLQzgCted6ewQiIjIhOZkIAK5eWktX3xBv7j/uFTQsh8NKBCIiE5WzieCqJbWYwW+3+dcT1C+HE63Q25ndwEREckzOJoLq0kJWNFbw79v9RNCwwns/ujl7QYmI5KCcTQQA7zqnlnV7O+kbjHnHCACObsluUCIiOSanE8Fli6oZiMV5s/U4VC6Agqh3LYGIiKQto4nAzK4xsy1mtt3M7kwxfYGZPW9mb5jZm2Z23USWf+nCKgBe3dXmPZugZokSgYjIBGUsEZhZGLgXuBZYDtxsZsuTqn0JeNQ5txK4CfjGRNZRVVrIuQ1lvLq7wyuoPVddQyIiE5TJPYLLge3OuZ3OuQHgEeCGpDoOqPCHZwEHJrqSyxZV8/qeDmJxB3XLoHMvDPaeVeAiIvkkk4lgLrAvMN7qlwXdBXzMzFqBp4DPTnQllzdV090/xKaDJ/wDxg7atp9hyCIi+SeT9xqyFGXJt/27GXjQOfdVM7sS+L6ZXeCci49akNltwG0AdXV1tLS0jEzr7/GqPvbrV+mtOsFlwMbfPM6RhrZJ25Dpqru7e1Rb5DO1RYLaIkFtkZ5MJoJWYH5gfB6ndv3cClwD4Jx7ycyiQC1wJFjJOXcfcB/AsmXLXHNzc3Aa/3PNL+kraeCy3383rL2D5fUFLA/UmalaWlpozoPtTIfaIkFtkaC2SE8mu4ZeA5aaWZOZFeIdDH4iqc5e4HcBzOx8IApM6B6xZsY75s5ifetxiES9J5bpgLGISNoylgicc0PAZ4BngU14Zwe9bWZ3m9n1frXPA39sZuuBh4FPuTN4asQ751Wy9XAXvQP+hWXHtk3WZoiIzHgZfR6Bc+4pvIPAwbIvB4Y3Aled7XounDeLWNyx8eBxLqk7F3a2QDzmXVsgIiLjyukri4e9c34lAOv3HYfaZRDrh47d2Q1KRCRHzIhE0FARpa68iLcPnPCuJQBdYSwikqYZkQgAzp9T4V9LsNQrUCIQEUnLDEoE5Ww/0s1g4SworYejSgQiIumYOYlgdgUDsTg7j570uoeO6RRSEZF0zJxEMMe7ZdFI95BOIRURScuMSQSL60opDIe8RFC9GPo6oac922GJiEx7MyYRRMIhljaUselQl5cIADp2ZTcoEZEcMGMSAcB5sysSewQA7UoEIiKnM6MSwflzyjna1c+xyByvoH1ndgMSEckBMyoRLPcPGG8+NgQVc5UIRETSMKMSwXnBM4eqFysRiIikYUYlgurSQhoqivxE0KREICKShhmVCMC/1cTwmUMnj0J/V7ZDEhGZ1mZcIjhvdgXbj3QxOKvJK9BegYjIuGZcIjh/TjmDMcc+6r2Cjj3ZDUhEZJqbcYng3IZyADb3VXsFnUoEIiLjmXGJoKm2lJDB5s4QFM3SHoGIyGnMuEQQjYSZX13CjiPdULVAewQiIqcx4xIBwJK6MrYf6YbKhdC5N9vhiIhMazMzETSUsevYSeLDicC5bIckIjJtzcxEUFfGQCxOR2Q2DPZ41xOIiEhKMzMR1JcBsNfpFFIRkdOZkYngHD8RbOnXKaQiIqczIxNBRTRCfXkRb3Z7N6FTIhARGduMTAQAi2pL2dYRh9I6dQ2JiIxj5iaCmhJ2HeuBSl1LICIynpmbCGpLOdbdz2DFfO0RiIiMY8YmgqaaUgA6CxvheCvEY1mOSERkepqxiWBRrZcIDlgDxAfhxIEsRyQiMj3N3ETg7xHsGqrxCnSrCRGRlGZsIiguDDO7IsrG3iqvQAeMRURSKsh2AJm0qLaE9V1hwHTAWERkDDN2jwC87qHtbYNQ0ag9AhGRMWQ0EZjZNWa2xcy2m9mdY9T5iJltNLO3zeyHk7n+RbWltJ0cYEinkIqIjCljXUNmFgbuBT4AtAKvmdkTzrmNgTpLgS8CVznnOsysfjJjGD5g3BVtpOrIK5O5aBGRGSOTewSXA9udczudcwPAI8ANSXX+GLjXOdcB4Jw7MpkBNPmnkB4JN0DXQYgNTubiRURmhEweLJ4L7AuMtwJXJNU5F8DMfguEgbucc88kL8jMbgNuA6irq6OlpSWtAAZi3gNp3jjiWObivPyLn9JX3DCxrZjGuru7026LmU5tkaC2SFBbpCeTicBSlCU/KqwAWAo0A/OAfzezC5xznaNmcu4+4D6AZcuWuebm5rSDaHz1OdrLz4UOWHVeIzS9O/0tmOZaWlqYSFvMZGqLBLVFgtoiPZnsGmoF5gfG5wHJl/e2Aj93zg0653YBW/ASw6RZVFuauB318X3jVxYRyUOZTASvAUvNrMnMCoGbgCeS6vwMeC+AmdXidRXtnMwgFtWWsrajxBvR1cUiIqfIWCJwzg0BnwGeBTYBjzrn3jazu83ser/as0CbmW0Engf+q3OubTLjWFRTwtFeiJc2QKf2CEREkmX0ymLn3FPAU0llXw4MO+Av/VdGDJ9C2lvSSOlx7RGIiCSb0VcWQ+IupB2Fs7VHICKSwoxPBPOrvOMDh63efy5BPMsRiYhML2klAjM7x8yK/OFmM/sLM6vMbGiTo7gwTH15EbtjNd5zCboPZTskEZFpJd09gp8AMTNbAnwbaAIm9b5AmbSwpoStfX7eUveQiMgo6SaCuH8W0B8BX3fO3QHMyVxYk2t+dQlvdulaAhGRVNJNBINmdjPwSeBJvyySmZAm38LqUtYPX1SmawlEREZJNxF8GrgS+Hvn3C4zawJ+kLmwJteCmmJ6iBKLVmmPQEQkSVrXEfi3jv4LADOrAsqdc1/JZGCTaUG1dwrpyeJGKnSMQERklHTPGmoxswozqwbWAw+Y2T9nNrTJs7DGO4W0I9KgriERkSTpdg3Ncs6dAP4/4AHn3CXA+zMX1uSqKS2kpDDMAeq8riGXfBNUEZH8lW4iKDCzOcBHSBwszhlmxoLqEnYPVsNgD/S0ZzskEZFpI91EcDfeDeJ2OOdeM7PFwLbMhTX5FtaUsKmvyhvRPYdEREaklQiccz92zl3onPtTf3ync+7DmQ1tci2oLmF9V7k3ogPGIiIj0j1YPM/MHjezI2Z22Mx+YmbzMh3cZFpQU8ruoRpvRAeMRURGpNs19ADeQ2Ua8Z5F/G9+Wc5YUF3CcUqJFZTqWgIRkYB0E0Gdc+4B59yQ/3oQqMtgXJNuYXUJYHQXz1HXkIhIQLqJ4JiZfczMwv7rY8CkPkks0+ZWFRMyaAs36GCxiEhAuongP+GdOnoIOAjciHfbiZwRCYdorCxmP3XaIxARCUj3rKG9zrnrnXN1zrl659yH8C4uyykLa0rYMVgFfZ3QdyLb4YiITAtn84SyjD1nOFMWVJewucd/LoEOGIuIAGeXCGzSopgiC6pL2aIH1IiIjHI2iSDnbtizsKaEVlfrjWiPQEQEOM1tqM2si9Rf+AYUZySiDFpQXcIxZhELFRLWRWUiIsBpEoFzrnyqApkKC2pKcIToKppNpfYIRESAs+sayjkV0QiVJRGOhut1mwkREV9eJQLwrjDeH6/VwWIREV/eJYIFNaVsH6yCk0dgsC/b4YiIZF3+JYLqYjb3Dl9L0JrdYEREpoG8SwQLq0vZGxs+hVTHCURE8i4RzK8uYf/wtQQ6TiAikn+JYGFNCYeoJm5hnTkkIkIeJoLZFVHC4QgnInVKBCIi5GEiCIWMedXFHArNho7d2Q5HRCTr8i4RgHctwe54vRKBiAgZTgRmdo2ZbTGz7WZ25zj1bjQzZ2aXZjKeYQuqS9jSX+1dSzBwcipWKSIybWUsEZhZGLgXuBZYDtxsZstT1CsH/gJ4JVOxJFtQU8q2Qf+Ryx17pmq1IiLTUib3CC4HtjvndjrnBoBHgBtS1Ps74B+BKbvMd2F1CXtdvTfSsWuqVisiMi2Ne/fRszQXCJ6o3wpcEaxgZiuB+c65J83sr8ZakJndBtwGUFdXR0tLy1kFdrgrPpIItr/2K1oPlZ7V8rKlu7v7rNtiplBbJKgtEtQW6clkIkj1BLORZxuYWQj4GvCp0y3IOXcfcB/AsmXLXHNz81kF1jsQ429++zT94VKW1BSw5CyXly0tLS2cbVvMFGqLBLVFgtoiPZnsGmoF5gfG5wEHAuPlwAVAi5ntBlYBT0zFAePiwjANFVGORhp15pCI5L1MJoLXgKVm1mRmhcBNwBPDE51zx51ztc65Rc65RcDLwPXOuTUZjGnEoppS9rl6aNcxAhHJbxlLBM65IeAzwLPAJuBR59zbZna3mV2fqfWma3FdKVsHaqFzD8Tj2Q5HRCRrMnmMAOfcU8BTSWVfHqNucyZjSdZUW8rWgRqIDEDXQZg1dypXLyIybeTllcUATbVl7HEN3oiOE4hIHsvjRFCqawlERMjjRLCguoRD1BAnrD0CEclreZsICgtCzKmuoD2im8+JSH7L20QAXvdQq1MiEJH8lveJYOtgLU7XEohIHsv7RLBrqA7rOQb9XdkOR0QkK/I+EewZOXNIt6MWkfyU94lg5BTS9p3ZDUZEJEvyOhE0zipmf9i/orhtW3aDERHJkrxOBKGQUV9TS0e4Bo5tz3Y4IiJZkdeJAPwDxsyFY1uzHYqISFYoEdSVsmmgHte2DZw7/QwiIjOMEkFtKdvijVjfcTh5LNvhiIhMubxPBItrS9np5ngj6h4SkTyU94ngnLoydrpGb0RnDolIHsr7RFBVWkh/SSODVgjHlAhEJP/kfSIAWNJQQWt4rhKBiOQlJQJgaUMZWwZne2cOiYjkGSUCYGl9GVtis737DQ31ZzscEZEppUQALG0oZ2d8DuZioFtSi0ieUSLA2yPYMXzm0LEt2Q1GRGSKKREANWVFtBU3ESMMhzZkOxwRkSmlROBrmlNLa3geHHoz26GIiEwpJQLfisYK1g3OxykRiEieUSLwXTB3FhtiC7ATB+BkW7bDERGZMkoEvhWNFWx0C72Rw29lNxgRkSmkROBrqi1jV3ixN3JIiUBE8ocSgS8cMhrmzKUtVAsH1mU7HBGRKaNEELCisYK1sSW4fa9kOxQRkSmjRBCwcn4VLw0txY7vg+P7sx2OiMiUUCIIuLypmtfiy7yRfS9nNxgRkSmiRBAwr6qYjrJl9FsU9ioRiEh+UCIIMDMuXlzHepbilAhEJE9kNBGY2TVmtsXMtpvZnSmm/6WZbTSzN83sOTNbmMl40nH5oipeGFgGhzfoYfYikhcylgjMLAzcC1wLLAduNrPlSdXeAC51zl0IPAb8Y6biSdcVi2t4Ln4x5uKw9ZlshyMiknGZ3CO4HNjunNvpnBsAHgFuCFZwzj3vnOvxR18G5mUwnrQsrS/jROV5HAvXw+b/m+1wREQyriCDy54L7AuMtwJXjFP/VuDpVBPM7DbgNoC6ujpaWlomKcTUls8a4snWlXx826/47XPPEA9HM7q+M9Xd3Z3xtsgVaosEtUWC2iI9mUwElqLMpaxo9jHgUuA9qaY75+4D7gNYtmyZa25unqQQUytZ2M7X7l/Pp+LP8jsNPXDBNRld35lqaWkh022RK9QWCWqLBLVFejLZNdQKzA+MzwMOJFcys/cDfwNc75ybFg8MvmRhFdujF9JW0ABrH8h2OCIiGZXJRPAasNTMmsysELgJeCJYwcxWAt/CSwJHMhjLhIRDxodQuGEAAA9DSURBVB+uXMAD/c2wazUc3ZrtkEREMiZjicA5NwR8BngW2AQ86px728zuNrPr/Wr/P1AG/NjM1pnZE2Msbsr9xyvm8/BgMzErgNfuz3Y4IiIZk8ljBDjnngKeSir7cmD4/Zlc/9lYUl/OkqYmnjnyO1y39rvYVbfDrLnZDktEZNLpyuJx/Kerm/iHnhtw8RiszvolDiIiGaFEMI7fW95AVeMSfhr6Pdzr34f9r2c7JBGRSadEMA4z4/O/dy53n/wQJyPV8LM/hcG+bIclIjKplAhO4z3n1nHVBUv4XM+tcHQzPPFZcCkvhxARyUlKBKdhZtzzoQtYV3Qp3y68Bd56FJ7+AsRj2Q5NRGRSKBGkoaasiHtvuZivnPwgT5b+Ebz6LfjhR6HrULZDExE5a0oEaVq1uIavfmQlt3d8hH8u+hPiu34D/+dyWP1P0NuZ7fBERM6YEsEEXP/ORn74x6v4kfsA7+v5B94Knwe//jvc1y6Af/sc7HkR4vFshykiMiEZvaBsJrq8qZrnPt/Mv7Zs5+OvLKCxfxt/bs/y/tcfoWjtgwyVzSG89P3YOe+FpvdAaW22QxYRGZcSwRkoKyrgv/7+eXz2fUt59u0VPLPpXfz91r1cNvAy1x5/jXe9/hMq3vg+AG3l59E790qKF19J1blXEarM+iMXRERGUSI4C9FImBsumssNF80lHr+ITYeaeXv/Cb5+oJ2+Pa8zu+1lLj++npUnfkDR5gfgKThqNewrXUFX9QUw+0JKFqxkduMC5syKUhBWT52ITD0lgkkSChkrGmexonEW3t2334lzn+JIVz9vHOqgc9cb0Poale3rWHByIxd3r4a9wKtw0FWz2i1iT+FSOmctI16zjOLZS5hfU0FjZZT68ij1FUUUFYSzvJUiMhMpEWSQmdFQEaWhYg6cOwe4bmTaUHc77TvWcnLP69ih9VzYsZHm3h8TaotDGwxsCbPbzWa7m8tvXSM74o0cKVpIT8ViZs2qpKG8iL6OAfYV7fbX4b1qywq1ZyEiE6JEkCUFZdXUv/MD8M4PJAoHeuDIJji2BQ5tYs6hLcxr28o13WsJuZj3fLfjcLSrjn2unh1DtezZU88a543vdQ20WQWVxYVUlRZSU1pIVUkhNWXee3Xp6FdFNEJFcYTyaAERJQ+RvKVEMJ0UlsC8S2DeJRQChcPlQ/3QvhOOboFjW6lr205dxx5WHH6LooH2UYsYDEVpL5xNe6yWw8er2N9Rzd7BWWztn8XBeBWHXBXtlOOSzhwujoQpjxaMJIaKaCTleHEkTGlRAcWFYUoiYUoK/WH/VVwYpjAcwizVk0pFZDpSIsgFBUVQf773CnippYXmq66Azr3QsRs69hDp2E1D5x4aug5y/om3ofsQuDhEEvPFQ4UMFFXTF5lFT8EsToYqOGHlHKecdlfKsaFyjnSWcGiwhI0DJbT2R2kbip6SPMYSDpmXJIr8RBFJJAkvYQQTSZiSogJveiRMNBKmqCBE1B+ORkIUFXjv0UiYaEGYokiIwnCIUEjJRmQyKBHkukgx1C3zXqnEhuDkEThxwHt1HSR0Yj/Rk8eI9rRT2dsOPXugpx16O7ykkawAXCSEi1YRi1YyVFhFf1El/ZFK+sLl9IZK6LESTlLCSSumyxVzPBblRLyYjniUzlgh7YMhuvqGOHKin57BIXr6Y/QMxOgdPPN7NkXCRlFBmMKCEG5okIrXnqcwHKKwIERRwfC7N70wHCISNiLhEJHkcX+eSNgoCA1PT0zzpnvjBaEQBWEjHDIKQkbIjIJwYDgUIhw2whao47+HQ4ky7THJdKJEMNOFC6Ci0XudTjwOfZ1eQuhph972kXfracd62wn1tBPpbae45zB0bIS+4zB4Mr1YCsugqBxKyqGyDApLcYWlxApKGAqXMBguZjBUzEC4mP5QMf1WTJ9F6bUofa6IXiL0uEJ64hHvRSEnYxF642H2tB6kuq6SgaE4A0Nx+v33zp4B+ofiDMbiDMZc0nuifKqFjEBiCBEyKAiHvLLhJBJIKMEkMno8NDrRmNHe1sfjh94YtRwvSRnhUIhwyDvLLWRGyCBkXmIySJSFDBuexnCdpOl4J0SMXs5wWfI8w8OnzkNwuZa03pCdMo8RWG4oMS8kljG8nLbeOAc6exPzBt69OfBixouDkXFG2oRAnWD+Ti4LzjNSliMJX4lAEkIhKKn2XjXnpD9fPAb9XSleJ8YvG+zBTuynYKCHgoGTRAdOekkl1V7JuIxYKEK4pxQKiiESTbwXDY9Hvb2nFO+uIEosHCUWKmIoXMRgqIjBUJQhChkMFzFAEQNWyIAV0kchg1ZEjBCxuGMo7oj777HAayjuiDlHLBb36ji/LOaXjzGvNxwnFodYPDBvzK8zPK+/nN7BWNJy4nR1xzky2Hnq8p23/uHYcBB3zn9NsMlzyW9+ne0Ixk8WfhJKLrNEbkokpaSy5GWPKk9a93iUCOTshcJQXOm9zpZzMNQHAydHvwZPeg8FGupN+b5/11YWzK4LlPfBYK/33tM+enz4fch7yJDh/SMUAEVpb3PEO3YTjkC4CMKF3vBIWWHSa3ha4eh5IsnzBIbHLE9eduGo8pYXXqT5ve89g6Z3uJHk4L0Pjzv89/jo5OFImifujTuCy0ixvBTrCdZLlI0eH1lv0vtwHfw4436cmzZv5txzl43EPxzjyPb6f3Iu0AaMlAWHE48hGd7mU+unnm+4cnB6YlmBeUaVpa6T/CgUF1h2YFWjYhievnacz16JQKYXM++XeqR4Qvdp2tnSwoLm5omtKx6HWP+pCWKwDwZ7UieP4Ht8yDujKzYAsUFvWcPDQ/3e+8BJiLX70wdgaMCvk/SaRM0Aq8OnJqFQgTccinhdhqHIqHELRbBwhNBp6iXGCxLvI9P84VBBou4pwxHvx0M4sJzga3h6cvkZdLO0dO+g+fIFk9q+ueofxpmmRCD5KxSCkJ90ssm5RKIY9RocO9HEBhLJJmm+Xdu30DR/7ujyoQGID3r144PeSQQj40PeNSynlKeoN1w+4e67SWCh0YnmlGQRDiQWb9rK7h7YWe0nktDousPzW3A5gToWHl1vVFnS+keWnapsrPWlG8M4ZZNEiUAk28y8bp2CwtPXTcOeoRaaJrp3NFHxmJcYRpLD0OhEEY8FyocTSqphv248sIzgsoNlsfHqpF5GrPeI96Xp4l5CHJkWAxdLqu+Pj5THRq/HTbenEtrpk5SFEsPjUCIQkYkb/jWb/lGVrHizpYXmyUqKznkJJTk5xGOnJicXTyqbYOIZVTeetL5UZaeJwcWANWNumhKBiEg6zBK/upmcvbep9d0xp+gGMyIieU6JQEQkzykRiIjkOSUCEZE8p0QgIpLnlAhERPKcEoGISJ5TIhARyXPmkm9nN82ZWRewJdtxTBO1wLFsBzFNqC0S1BYJaouEhc65ulQTcvHK4i3OuUuzHcR0YGZr1BYetUWC2iJBbZEedQ2JiOQ5JQIRkTyXi4ngvmwHMI2oLRLUFglqiwS1RRpy7mCxiIhMrlzcIxARkUmkRCAikudyKhGY2TVmtsXMtpvZndmOJ9PM7DtmdsTMNgTKqs3sl2a2zX+v8svNzP7Fb5s3zezi7EU++cxsvpk9b2abzOxtM/ucX5537WFmUTN71czW+23xP/zyJjN7xW+LH5lZoV9e5I9v96cvymb8mWBmYTN7w8ye9Mfzti3ORM4kAjMLA/cC1wLLgZvNbHl2o8q4B4FrksruBJ5zzi0FnvPHwWuXpf7rNuBfpyjGqTIEfN45dz6wCvhz//PPx/boB97nnHsncBFwjZmtAv4X8DW/LTqAW/36twIdzrklwNf8ejPN54BNgfF8bouJc87lxAu4Eng2MP5F4IvZjmsKtnsRsCEwvgWY4w/PwbvADuBbwM2p6s3EF/Bz4AP53h5ACfA6cAXeFbQFfvnI/wvwLHClP1zg17Nsxz6JbTAP70fA+4AnAcvXtjjTV87sEQBzgX2B8Va/LN80OOcOAvjv9X553rSPvzu/EniFPG0PvytkHXAE+CWwA+h0zg35VYLbO9IW/vTjQM3URpxRXwf+Goj74zXkb1uckVxKBJaiTOe+JuRF+5hZGfAT4Hbn3InxqqYomzHt4ZyLOecuwvs1fDlwfqpq/vuMbQsz+wPgiHNubbA4RdUZ3xZnI5cSQSswPzA+DziQpViy6bCZzQHw34/45TO+fcwsgpcEHnLO/dQvztv2AHDOdQIteMdNKs1s+P5hwe0daQt/+iygfWojzZirgOvNbDfwCF730NfJz7Y4Y7mUCF4DlvpnAxQCNwFPZDmmbHgC+KQ//Em8vvLh8k/4Z8usAo4Pd5nMBGZmwLeBTc65fw5Myrv2MLM6M6v0h4uB9+MdKH0euNGvltwWw210I/Br53eS5zrn3Bedc/Occ4vwvhN+7Zy7hTxsi7OS7YMUE3kB1wFb8fpD/ybb8UzB9j4MHAQG8X7J3IrXn/kcsM1/r/brGt5ZVTuAt4BLsx3/JLfF1Xi78G8C6/zXdfnYHsCFwBt+W2wAvuyXLwZeBbYDPwaK/PKoP77dn74429uQoXZpBp5UW0z8pVtMiIjkuVzqGhIRkQxQIhARyXNKBCIieU6JQEQkzykRiIjkOSUCkSlkZs3Dd8gUmS6UCERE8pwSgUgKZvYx/57/68zsW/5N3rrN7Ktm9rqZPWdmdX7di8zsZf+5B48HnomwxMx+5T834HUzO8dffJmZPWZmm83sIf+qaZGsUSIQSWJm5wMfBa5y3o3dYsAtQCnwunPuYuA3wN/6s3wP+IJz7kK8q5iHyx8C7nXecwPehXeVOHh3Tr0d77kai/HulyOSNQWnryKSd34XuAR4zf+xXox3M7s48CO/zg+An5rZLKDSOfcbv/y7wI/NrByY65x7HMA51wfgL+9V51yrP74O75kTL2R+s0RSUyIQOZUB33XOfXFUodl/T6o33v1Zxuvu6Q8Mx9D/oWSZuoZETvUccKOZ1cPIc5EX4v2/DN/R8j8CLzjnjgMdZvZuv/zjwG+c96yEVjP7kL+MIjMrmdKtEEmTfomIJHHObTSzLwG/MLMQ3t1f/xw4Cawws7V4T7b6qD/LJ4Fv+l/0O4FP++UfB75lZnf7y/gPU7gZImnT3UdF0mRm3c65smzHITLZ1DUkIpLntEcgIpLntEcgIpLnlAhERPKcEoGISJ5TIhARyXNKBCIiee7/AXimO97dwe+sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.title('Model performance throughout training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfomance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scaled = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122579.14],\n",
       "       [167903.05],\n",
       "       [182313.8 ],\n",
       "       ...,\n",
       "       [168551.69],\n",
       "       [112576.3 ],\n",
       "       [241433.36]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse_transform\n",
    "# exponentiel \n",
    "\n",
    "log_prediction = scaler_Y_log.inverse_transform(prediction_scaled)\n",
    "prediction = np.expm1(log_prediction)\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_ID\n",
    "submission['SalePrice'] =  prediction\n",
    "submission.to_csv('Keras-Numfeatures.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
